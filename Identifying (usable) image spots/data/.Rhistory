plotRGB(wsi)
e <- extent(13091, 13341, 4639, 4889)
cropped_img <- crop(wsi, e)
plotRGB(cropped_img)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/colten/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
barcodes <- barcode_feature_matrix@Dimnames[2][[1]]
features <- barcode_feature_matrix@Dimnames[1][[1]]
indexes_of_training_barcodes <- match(image_location$barcode[training_indexes], barcodes)
set.seed(1998)
#nrow should be used when looking at the entire data set and no longer restricting to 500 spots
index <- sample(2,
500, #nrow(image_location),
replace = TRUE,
prob = c(0.7, 0.3)) #splits data into testing and training
training_data <- array(NA, dim=c(sum(index == 1), 272, 272, 3))
index_count <- 1
training_indexes <- which(index == 1)
print("Collecting training data")
pb <- txtProgressBar(min = 0, max = length(training_indexes), style = 3)
for (i in training_indexes) #This for loop takes about an hour and a half when run on all spots
{
cropped_img <- crop_spot(wsi,
image_location$pxl_row_in_fullres_xValue[i],
image_location$pxl_col_in_fullres_yValue[i])
#Manipulate colors??
#plotRGB(cropped_img)
cropped_img <- as.array(cropped_img)
training_data[index_count,,,] <- cropped_img
setTxtProgressBar(pb, index_count)
index_count <- index_count + 1
}
close(pb)
#dim(training_data)
testing_data <- array(NA, dim=c(sum(index == 2), 272, 272, 3))
index_count <- 1
testing_indexes <- which(index == 2)
print("Collecting testing data")
pb <- txtProgressBar(min = 0, max = length(testing_indexes), style = 3)
for (i in testing_indexes) #This for loop takes about 40 mins when run on all spots
{
cropped_img <- crop_spot(wsi,
image_location$pxl_row_in_fullres_xValue[i],
image_location$pxl_col_in_fullres_yValue[i])
#plotRGB(cropped_img)
cropped_img <- as.array(cropped_img)
testing_data[index_count,,,] <- cropped_img
setTxtProgressBar(pb, index_count)
index_count <- index_count + 1
}
close(pb)
#dim(testing_data)
set.seed(1998)
#nrow should be used when looking at the entire data set and no longer restricting to 500 spots
index <- sample(2,
500, #nrow(image_location),
replace = TRUE,
prob = c(0.7, 0.3)) #splits data into testing and training
training_data <- array(NA, dim=c(sum(index == 1), 272, 272, 3))
index_count <- 1
training_indexes <- which(index == 1)
print("Collecting training data")
pb <- txtProgressBar(min = 0, max = length(training_indexes), style = 3)
for (i in training_indexes) #This for loop takes about an hour and a half when run on all spots
{
cropped_img <- crop_spot(wsi,
image_location$pxl_row_in_fullres_xValue[i],
image_location$pxl_col_in_fullres_yValue[i])
#Manipulate colors??
#plotRGB(cropped_img)
cropped_img <- as.array(cropped_img)
training_data[index_count,,,] <- cropped_img
setTxtProgressBar(pb, index_count)
index_count <- index_count + 1
}
close(pb)
#dim(training_data)
testing_data <- array(NA, dim=c(sum(index == 2), 272, 272, 3))
index_count <- 1
testing_indexes <- which(index == 2)
print("Collecting testing data")
pb <- txtProgressBar(min = 0, max = length(testing_indexes), style = 3)
for (i in testing_indexes) #This for loop takes about 40 mins when run on all spots
{
cropped_img <- crop_spot(wsi,
image_location$pxl_row_in_fullres_xValue[i],
image_location$pxl_col_in_fullres_yValue[i])
#plotRGB(cropped_img)
cropped_img <- as.array(cropped_img)
testing_data[index_count,,,] <- cropped_img
setTxtProgressBar(pb, index_count)
index_count <- index_count + 1
}
close(pb)
#dim(testing_data)
}
?match()
install.packages("neuralnet")
install.packages("neuralnet")
library(neuralnet)
set.seed(1998)
#nrow should be used when looking at the entire data set and no longer restricting to 500 spots
index <- sample(2,
500, #nrow(image_location),
replace = TRUE,
prob = c(0.7, 0.3)) #splits data into testing and training
training_data <- array(NA, dim=c(sum(index == 1), 272, 272, 3))
index_count <- 1
training_indexes <- which(index == 1)
print("Collecting training data")
pb <- txtProgressBar(min = 0, max = length(training_indexes), style = 3)
for (i in training_indexes) #This for loop takes about an hour and a half when run on all spots
{
cropped_img <- crop_spot(wsi,
image_location$pxl_row_in_fullres_xValue[i],
image_location$pxl_col_in_fullres_yValue[i])
#Manipulate colors??
#plotRGB(cropped_img)
cropped_img <- as.array(cropped_img)
training_data[index_count,,,] <- cropped_img
setTxtProgressBar(pb, index_count)
index_count <- index_count + 1
}
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
?GetAssayData()
feature_matrix
View(feature_matrix)
?match()
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
barcodes <- barcode_feature_matrix@Dimnames[2][[1]]
barcodes
View(barcode_feature_matrix)
features <- barcode_feature_matrix@Dimnames[1][[1]]
?fit()
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
barcodes <- barcode_feature_matrix@Dimnames[2][[1]]
features <- barcode_feature_matrix@Dimnames[1][[1]]
indexes_of_training_barcodes <- match(image_location$barcode[training_indexes], barcodes)
training_barcode_feature_matrix <- t(barcode_feature_matrix[,indexes_of_training_barcodes])
indexes_of_training_barcodes <- match(image_location$barcode[training_indexes], barcodes)
training_barcode_feature_matrix <- t(barcode_feature_matrix[,indexes_of_training_barcodes])
install.packages("neuralnet")
library(neuralnet)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
barcodes <- barcode_feature_matrix@Dimnames[2][[1]]
features <- barcode_feature_matrix@Dimnames[1][[1]]
indexes_of_training_barcodes <- match(image_location$barcode[training_indexes], barcodes)
install.packages("neuralnet")
library(neuralnet)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
install.packages("neuralnet")
library(neuralnet)
library(Seurat)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
install.packages("neuralnet")
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
barcodes <- barcode_feature_matrix@Dimnames[2][[1]]
features <- barcode_feature_matrix@Dimnames[1][[1]]
indexes_of_training_barcodes <- match(image_location$barcode[training_indexes], barcodes)
#install.packages("neuralnet")
library(neuralnet)
library(Seurat)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
barcodes <- barcode_feature_matrix@Dimnames[2][[1]]
features <- barcode_feature_matrix@Dimnames[1][[1]]
indexes_of_training_barcodes <- match(image_location$barcode[training_indexes], barcodes)
#install.packages("neuralnet")
library(neuralnet)
library(Seurat)
image_location <- read.csv("data/spatial/tissue_positions_list.csv", header=FALSE)
getwd()
image_location <- read.csv("C:/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data/spatial/tissue_positions_list.csv", header=FALSE)
names(image_location) <- c("barcode", "in_tissue", "array_row", "array_col", "pxl_col_in_fullres_yValue", "pxl_row_in_fullres_xValue")
file_name <- 'data/V1_Breast_Cancer_Block_A_Section_1_image.tif'
wsi <- brick(file_name)
#install.packages("neuralnet")
library(neuralnet)
library(Seurat)
library(raster)
image_location <- read.csv("C:/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data/spatial/tissue_positions_list.csv", header=FALSE)
names(image_location) <- c("barcode", "in_tissue", "array_row", "array_col", "pxl_col_in_fullres_yValue", "pxl_row_in_fullres_xValue")
file_name <- 'data/V1_Breast_Cancer_Block_A_Section_1_image.tif'
#creates a raster object from the tiff image file
#imported_raster <- raster(str_name)
wsi <- brick(file_name)
#creates a raster object from the tiff image file
#imported_raster <- raster(str_name)
wsi <- brick(file_name)
file_name <- 'data/V1_Breast_Cancer_Block_A_Section_1_image.tif'
wsi <- brick(file_name)
dim(wsi)
plotRGB(wsi)
e <- extent(13091, 13341, 4639, 4889)
plotRGB(cropped_img)
?sample()
#devtools::install_github("satijalab/seurat", ref = "spatial")
library(backports)
library(Seurat)
#library(SeuratData)
library(ggplot2)
library(patchwork)
library(dplyr)
library(Matrix)
library(rjson)
library(cowplot)
library(RColorBrewer)
library(grid)
library(readbitmap)
library(hdf5r)
library(data.table)
library(raster)
library(keras)
library(EBImage)
index <- 1:10
par(mfcol = c(2,5), mar = rep(1, 4), oma = rep(0.2, 4))
training_data[index,,,] %>%
purrr::array_tree(1) %>%
purrr::map(as.raster, max = 255) %>%
purrr::iwalk(~{plot(.x)})
# Fix structure for 2d CNN
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu",
input_shape = c(272,272,3)) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2))
summary(model)
set.seed(1998)
#nrow should be used when looking at the entire data set and no longer restricting to 500 spots
index <- sample(2,
500, #nrow(image_location),
replace = TRUE,
prob = c(0.7, 0.3))
print(index)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
barcodes <- barcode_feature_matrix@Dimnames[2][[1]]
features <- barcode_feature_matrix@Dimnames[1][[1]]
#matches the barcode from image_location to the barcode in the barcodes list (Seurat object)
indexes_of_training_barcodes <- match(image_location$barcode[training_indexes], barcodes)
training_barcode_feature_matrix <- t(barcode_feature_matrix[,indexes_of_training_barcodes])
#devtools::install_github("satijalab/seurat", ref = "spatial")
library(backports)
library(Seurat)
#library(SeuratData)
library(ggplot2)
library(patchwork)
library(dplyr)
library(Matrix)
library(rjson)
library(cowplot)
library(RColorBrewer)
library(grid)
library(readbitmap)
library(hdf5r)
library(data.table)
library(raster)
library(keras)
library(EBImage)
library(stringr)
library(pbapply)
library(stringr)
library(pbapply)
# Load in spot location CSV file(doesn't have headers)
image_location <- read.csv("data/spatial/tissue_positions_list.csv", header=FALSE)
names(image_location) <- c("barcode", "in_tissue", "array_row", "array_col", "pxl_col_in_fullres_yValue", "pxl_row_in_fullres_xValue")
file_name <- 'data/V1_Breast_Cancer_Block_A_Section_1_image.tif'
#creates a raster object from the tiff image file
#imported_raster <- raster(str_name)
wsi <- brick(file_name)
#check to see the image contains the correct amount of pixels
dim(wsi)
plotRGB(wsi)
e <- extent(13091, 13341, 4639, 4889)
cropped_img <- crop(wsi, e)
plotRGB(cropped_img)
image_location <- image_location %>%
filter(in_tissue == 1)
crop_spot <- function(img, x, y){
e <- extent(x - 136, #using 136 since it is ~half the average distance (273 pixels) between spot centers. We could consider using a different measure to more closely fit to the spot ratius.
x + 136,
y - 136,
y + 136)
cropped_img <- crop(img, e)
return(cropped_img)
}
set.seed(1998)
#nrow should be used when looking at the entire data set and no longer restricting to 500 spots
index <- sample(2,
nrow(image_location),
replace = TRUE,
prob = c(0.7, 0.3))
training_data <- array(NA, dim=c(sum(index == 1), 272*272))
index
training_data <- array(NA, dim=c(sum(index == 1), 272*272))
training_indexes <- which(index == 1)
print("Collecting training data")
for (i in training_indexes) #This for loop takes about an hour and a half when run on all spots
{
cropped_img <- crop_spot(wsi,
image_location$pxl_row_in_fullres_xValue[i],
image_location$pxl_col_in_fullres_yValue[i])
#Manipulate colors??
#plotRGB(cropped_img)
cropped_img <- as.array(cropped_img)
training_data[index_count,] <- as.array(as.vector(cropped_img[,,1]))
setTxtProgressBar(pb, index_count)
index_count <- index_count + 1
}
#devtools::install_github("satijalab/seurat", ref = "spatial")
library(backports)
library(Seurat)
#library(SeuratData)
library(ggplot2)
library(patchwork)
library(dplyr)
library(Matrix)
library(rjson)
library(cowplot)
library(RColorBrewer)
library(grid)
library(readbitmap)
library(hdf5r)
library(data.table)
library(raster)
library(keras)
library(EBImage)
library(stringr)
library(pbapply)
image_location <- read.csv("data/spatial/tissue_positions_list.csv", header=FALSE)
names(image_location) <- c("barcode", "in_tissue", "array_row", "array_col",
image_location <- read.csv("data/spatial/tissue_positions_list.csv", header=FALSE)
names(image_location) <- c("barcode", "in_tissue", "array_row", "array_col", "pxl_col_in_fullres_yValue", "pxl_row_in_fullres_xValue")
# Load in spot location CSV file(doesn't have headers)
image_location <- read.csv("data/spatial/tissue_positions_list.csv", header=FALSE)
file_name <- 'data/V1_Breast_Cancer_Block_A_Section_1_image.tif'
#creates a raster object from the tiff image file
#imported_raster <- raster(str_name)
wsi <- brick(file_name)
#check to see the image contains the correct amount of pixels
dim(wsi)
plotRGB(wsi)
plotRGB(wsi)
e <- extent(13091, 13341, 4639, 4889)
cropped_img <- crop(wsi, e)
plotRGB(cropped_img)
# grabbing only the spots with tissue
image_location <- image_location %>%
filter(in_tissue == 1)
# Load in spot location CSV file(doesn't have headers)
image_location <- read.csv("data/spatial/tissue_positions_list.csv", header=FALSE)
names(image_location) <- c("barcode", "in_tissue", "array_row", "array_col", "pxl_col_in_fullres_yValue", "pxl_row_in_fullres_xValue")
file_name <- 'data/V1_Breast_Cancer_Block_A_Section_1_image.tif'
#creates a raster object from the tiff image file
#imported_raster <- raster(str_name)
wsi <- brick(file_name)
#check to see the image contains the correct amount of pixels
dim(wsi)
plotRGB(wsi)
e <- extent(13091, 13341, 4639, 4889)
cropped_img <- crop(wsi, e)
plotRGB(cropped_img)
# grabbing only the spots with tissue
image_location <- image_location %>%
filter(in_tissue == 1)
#defining a function to get a cropped spot image given the x and y coordinates of the center of the spot
crop_spot <- function(img, x, y){
e <- extent(x - 136, #using 136 since it is ~half the average distance (273 pixels) between spot centers. We could consider using a different measure to more closely fit to the spot ratius.
x + 136,
y - 136,
y + 136)
cropped_img <- crop(img, e)
return(cropped_img)
}
set.seed(1998)
#nrow should be used when looking at the entire data set and no longer restricting to 500 spots
index <- sample(2,
nrow(image_location),
replace = TRUE,
prob = c(0.7, 0.3)) #splits data into testing and training
training_data <- array(NA, dim=c(sum(index == 1), 272*272))
index_count <- 1
print("Collecting training data")
pb <- txtProgressBar(min = 0, max = length(training_indexes), style = 3)
for (i in training_indexes) #This for loop takes about an hour and a half when run on all spots
{
cropped_img <- crop_spot(wsi,
image_location$pxl_row_in_fullres_xValue[i],
image_location$pxl_col_in_fullres_yValue[i])
#Manipulate colors??
#plotRGB(cropped_img)
cropped_img <- as.array(cropped_img)
training_data[index_count,] <- as.array(as.vector(cropped_img[,,1]))
setTxtProgressBar(pb, index_count)
index_count <- index_count + 1
}
testing_data <- array(NA, dim=c(sum(index == 2), 272*272))
index_count <- 1
testing_indexes <- which(index == 2)
print("Collecting testing data")
pb <- txtProgressBar(min = 0, max = length(testing_indexes), style = 3)
for (i in testing_indexes) #This for loop takes about 40 mins when run on all spots
{
cropped_img <- crop_spot(wsi,
image_location$pxl_row_in_fullres_xValue[i],
image_location$pxl_col_in_fullres_yValue[i])
#plotRGB(cropped_img)
cropped_img <- as.array(cropped_img)
testing_data[index_count,] <- as.array(as.vector(cropped_img[,,1]))
setTxtProgressBar(pb, index_count)
index_count <- index_count + 1
}
close(pb)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/colten/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
feature_matrix <- Load10X_Spatial(data.dir = "/Users/malih/Desktop/Perkins_Lab_ST/Identifying (usable) image spots/data",
filename = "V1_Breast_Cancer_Block_A_Section_1_filtered_feature_bc_matrix.h5",
assay = "Spatial",
slice = "slice1",
filter.matrix = TRUE,
to.upper = FALSE)
barcode_feature_matrix <- GetAssayData(object = feature_matrix, slot = "counts")
barcodes <- barcode_feature_matrix@Dimnames[2][[1]]
features <- barcode_feature_matrix@Dimnames[1][[1]]
indexes_of_training_barcodes <- match(image_location$barcode[training_indexes], barcodes)
training_barcode_feature_matrix <- t(barcode_feature_matrix[,indexes_of_training_barcodes])
dim(training_barcode_feature_matrix)
indexes_of_testing_barcodes <- match(image_location$barcode[testing_indexes], barcodes)
testing_barcode_feature_matrix <- t(barcode_feature_matrix[,indexes_of_testing_barcodes])
dim(testing_barcode_feature_matrix)
# define and compile model
# expected input data shape: (batch_size, timesteps, data_dim)
model <- keras_model_sequential()
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = ncol(training_data)) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = ncol(training_barcode_feature_matrix), activation = "softmax")
summary(model)
compile(model, loss = 'categorical_crossentropy', optimizer = optimizer_rmsprop(), metrics = "accuracy")
# generate dummy training data
# x_train <- array(runif(1000 * timesteps * data_dim), dim = c(1000, timesteps, data_dim))
# y_train <- matrix(runif(1000 * num_classes), nrow = 1000, ncol = num_classes)
# dim(y_train)
# # generate dummy validation data
# x_val <- array(runif(100 * timesteps * data_dim), dim = c(100, timesteps, data_dim))
# y_val <- matrix(runif(100 * num_classes), nrow = 100, ncol = num_classes)
# train
model %>% fit(
training_data, training_barcode_feature_matrix, batch_size = 32, epochs = 10
)
#test
score = model %>% evaluate(testing_data, testing_barcode_feature_matrix, batch_size=32)
#show predictions
features <- model %>% predict(testing_data)
